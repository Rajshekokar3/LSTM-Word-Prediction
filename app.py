import streamlit as st
import numpy as np
import pandas as pd
import pickle
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences


#load model
model=load_model('next_word_lstm.h5')

#Load tokenizer
with open('tokenizer.pickle','rb') as file:
    tokenizer=pickle.load(file)

#Function to predict the next word
def predict_next_word(model,tokenizer,text,max_sequence_len):
  token_list=tokenizer.texts_to_sequences([text])[0]
  if len(token_list)>= max_sequence_len:
    token_list=token_list[-(max_sequence_len-1):]#Ebsure the sequence length match max_sequence

  token_list=pad_sequences([token_list],maxlen=max_sequence_len-1, padding='pre')
  predicted=model.predict(token_list,verbose=0)
  predicted_word_index=np.argmax(predicted,axis=1)
  for word,index in tokenizer.word_index.items():
    if index == predicted_word_index:
      return word

#Steeamlit App
st.title("Next Word Prediction with lstm and Early Stopping")
input_text=st.text_input("Enter the word","TO be or not to")
if st.button("Predict Next Word"):
  max_sequences_len=model.input_shape[1]+1
  next_word=predict_next_word(model,tokenizer,input_text,max_sequences_len)
  st.write(f"Next word:{next_word}")
